{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891bbb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a new model\n",
    "import numpy as np\n",
    "import torch\n",
    "from backbone import backbone_model, criterions_and_optimizers, training_page\n",
    "from scipy.special import softmax\n",
    "from load_config import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleMultiHeadCNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, num_classes=10, heads_num=3, conv_layers_config=[16, 32], fc_layers_config=[], dropout_prob=0.2):\n",
    "        \"\"\"\n",
    "        A simple configurable multi-head CNN.\n",
    "\n",
    "        Parameters:\n",
    "        - input_channels: Number of channels in input images\n",
    "        - num_classes: Number of output classes per head\n",
    "        - heads_num: Number of classification heads\n",
    "        - conv_layers_config: List of integers, number of filters per conv layer\n",
    "        - fc_layers_config: List of integers, number of neurons per fully connected layer, NOT including linear classifier layer (last one)\n",
    "        - dropout_prob: Dropout probability in FC layers\n",
    "        \"\"\"\n",
    "        super(SimpleMultiHeadCNN, self).__init__()\n",
    "        \n",
    "        # Build convolutional backbone\n",
    "        layers = []\n",
    "        in_ch = input_channels\n",
    "        for out_ch in conv_layers_config:\n",
    "            layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "            in_ch = out_ch\n",
    "        layers.append(nn.AdaptiveAvgPool2d((1,1)))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        # Flatten size after conv layers (assuming square input)\n",
    "        self.flatten_size = in_ch  # placeholder, will compute dynamically in forward if needed\n",
    "        \n",
    "        # Build multi-heads\n",
    "        self.classification_heads = nn.ModuleList()\n",
    "        for _ in range(heads_num):\n",
    "            head_layers = []\n",
    "            prev_size = self.flatten_size\n",
    "            for fc_size in fc_layers_config:\n",
    "                head_layers.append(nn.Linear(prev_size, fc_size))\n",
    "                head_layers.append(nn.ReLU())\n",
    "                head_layers.append(nn.Dropout(dropout_prob))\n",
    "                prev_size = fc_size\n",
    "            head_layers.append(nn.Linear(prev_size, num_classes))\n",
    "            self.classification_heads.append(nn.Sequential(*head_layers))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional backbone\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Pass through each head\n",
    "        outputs = []\n",
    "        for head in self.classification_heads:\n",
    "            outputs.append(head(x))\n",
    "        return outputs\n",
    "\n",
    "def main(current_config):\n",
    "    best_val_loss = np.ones(config['general']['heads_num'])*np.inf\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_loader, val_loader, test_loader, cal_loader=load_data(current_config)\n",
    "    model = ModifiedResNet50(current_config).to(device)\n",
    "    optimizer = set_optimizer(model,current_config)\n",
    "    criterion = set_criterion(current_config)\n",
    "    if current_config['current_step']['training_phase'][0]==\"retrain\" or current_config['current_step']['training_phase'][0]==\"eval\":\n",
    "        model,_=load_best_weights(model, optimizer, config['general']['save_path'])\n",
    "    if not current_config['current_step']['training_phase'][0]==\"eval\":\n",
    "        model,best_val_loss=training_loop(model,train_loader,val_loader,optimizer,criterion,device,best_val_loss,current_config)\n",
    "    test_loss, test_accuracy,test_output,test_targets = evaluate_individual_heads(model, test_loader, criterion, device)\n",
    "    cal_loss, cal_accuracy,cal_output,cal_targets = evaluate_individual_heads(model, cal_loader, criterion, device)\n",
    "    print(f\"Cal average accuracy:{np.array(cal_accuracy).mean()}\")\n",
    "    print(f\"Test average accuracy:{np.array(test_accuracy).mean()}\")\n",
    "    print(f\"Train sampels:{len(train_loader.dataset)}\\nVal sampels:{len(val_loader.dataset)}\\nTest sampels:{test_targets.shape[0]}\\nCAL sampels:{cal_targets.shape[0]}\")\n",
    "    if config['general']['save_output'][0] and current_config['current_step']['training_phase'][0]==\"eval\":\n",
    "        save_dir = config['general']['save_output'][1]\n",
    "        save_name=config['general']['save_output'][2]\n",
    "        np.save(f\"{save_dir}/test_outputs_{config['general']['dataset_name']}_{save_name}.npy\", softmax(test_output,axis=2))\n",
    "        np.save(f\"{save_dir}/cal_outputs_{config['general']['dataset_name']}_{save_name}.npy\", softmax(cal_output,axis=2))\n",
    "        np.save(f\"{save_dir}/cal_target_{config['general']['dataset_name']}_{save_name}.npy\", cal_targets)\n",
    "        np.save(f\"{save_dir}/test_target_{config['general']['dataset_name']}_{save_name}.npy\", test_targets)\n",
    "    print(f\"Test Loss: {np.array(test_loss).mean()}, Test Accuracy: {np.array(test_accuracy).mean()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config=load_config()\n",
    "    current_config={}\n",
    "    current_config['current_step']={}\n",
    "    current_config['current_step']['batch_size']= config['general']['batch_size']\n",
    "    current_config['current_step']['dropout_prob']= config['general']['dropout_prob']\n",
    "    current_config['current_step']['num_layers']= config['general']['num_layers']\n",
    "    current_config['current_step']['optimizer_name']=config['general']['optimizer_name']\n",
    "    current_config['current_step']['weight_decay'] = config['general']['weight_decay']\n",
    "    for step_index, s in enumerate(config['training_plan'].values()):\n",
    "        current_config['current_step']['trained_heads'] = s['trained_heads']\n",
    "        current_config['current_step']['training_phase'] = s['training_phase']\n",
    "        current_config['current_step']['num_epochs'] = s['num_epochs']\n",
    "        current_config['current_step']['criterion_name'] = s['criterion_name']\n",
    "        current_config['current_step']['lr_features']= s['lr_features']\n",
    "        current_config['current_step']['lr_heads'] = s['lr_heads']\n",
    "        print(current_config['current_step'])\n",
    "        main(current_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc26bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data, compute_scores, generate_Dcal_Dcells_sets, create_random_split\n",
    "from multi_dim_cp import main_algo\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from matplotlib.patches import Patch\n",
    "from utils import create_true_rest_sets\n",
    "from tabulate import tabulate\n",
    "\n",
    "np.random.seed(5)\n",
    "\n",
    "config={\n",
    "    'DATASET_NAME': 'PathMNIST_demo', # CIFAR100_demo, PathMNIST_demo\n",
    "    \n",
    "    'ALPHA': 0.2,\n",
    "    \n",
    "    'b': 1, # Always 1\n",
    "    \n",
    "    'N_HEADS': [1,2,4,7],\n",
    "    \n",
    "    'SCORING_METHOD': 'RAPS' # RAPS, SAPS , NAIVE , APS\n",
    "    \n",
    "}\n",
    "\n",
    "cal_output,cal_target,test_output,test_target=load_data(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
